## ШІ-агент для резюмування текстів

Веб-інтерфейс (Django) для резюмування текстів, PDF, Word-документів, таблиць і зображень з використанням багатомовних трансформерних моделей. З історією запитів для авторизованих користувачів (PostgreSQL).

## Теоретичні основи проекту

### 1. Архітектура системи

Проект реалізує комплексну систему автоматизованого резюмування документів на основі архітектури з кількома взаємопов'язаними модулями:

#### 1.1 Модуль завантаження та попередньої обробки
- **Мета**: Уніфіковане зчитування різних форматів документів
- **Підтримувані формати**: 
  - Текстові: `.txt`, `.pdf` (PyMuPDF), `.docx` (python-docx)
  - Табличні: `.csv`, `.xlsx` (pandas)
  - Графічні: `.jpg`, `.png` (OCR через pytesseract)
- **Алгоритм**: Визначення типу файлу за розширенням → виклик відповідного парсера → повернення уніфікованого текстового представлення

#### 1.2 NLP-пайплайн
- **Токенізація**: Використання спеціалізованих токенайзерів для трансформерних моделей
- **Чанкінг**: Розбиття довгих текстів на перекриті сегменти (512 токенів для CPU, 256 для GPU)
- **Адаптивний розрахунок довжини**: Комбінований підхід з факторами адаптації під розмір тексту та кількість чанків (базові межі 60-150 слів)
- **Сумаризація**: Застосування попередньо натренованих моделей seq2seq з оптимізацією для CPU/GPU
- **Витягнення фактів**: Регулярні вирази + евристичні методи для виділення чисел, дат, сутностей
- **Вибір пристрою**: Можливість вибору CPU/GPU через веб-інтерфейс або CLI параметри
- **Оптимізація для великих текстів**: Автоматичне переключення на CPU для текстів >5000 слів

#### 1.3 Постпроцесинг
- **Збірка результатів**: Об'єднання резюме чанків у когерентний текст
- **Форматування**: Структурування на коротке/розширене резюме + факти
- **Експорт**: Генерація `.txt` та `.pdf` з підтримкою Unicode

### 2. Математичні основи

#### 2.1 Токенізація
Для моделі mT5 використовується SentencePiece токенайзер:
```
T = Tokenizer(text)
tokens = T.encode(text, add_special_tokens=False)
```

#### 2.2 Чанкінг з перекриттям
Алгоритм розбиття тексту на сегменти:
```
chunks = []
start = 0
while start < len(tokens):
    end = min(start + max_tokens, len(tokens))
    chunk = tokens[start:end]
    chunks.append(decode(chunk))
    start = end - overlap_tokens
```

#### 2.3 Сумаризація
Використання архітектури T5 (Text-to-Text Transfer Transformer):
- **Encoder**: Перетворює вхідний текст у контекстуальні представлення
- **Decoder**: Генерує резюме на основі контексту
- **Attention**: Механізм уваги для фокусування на важливих частинах тексту

### 3. Технологічний стек

#### 3.1 Машинне навчання
- **PyTorch**: Основа для роботи з трансформерними моделями
- **Transformers**: Бібліотека Hugging Face для доступу до попередньо натренованих моделей
- **SentencePiece**: Токенайзер для багатомовних моделей

#### 3.2 Обробка документів
- **PyMuPDF (fitz)**: Витягнення тексту з PDF
- **python-docx**: Парсинг Word документів
- **pandas**: Обробка табличних даних
- **pytesseract**: OCR для зображень

#### 3.3 Інтерфейс користувача
- **Django**: Веб-додаток (автентифікація, історія, чат-подібний інтерфейс)
- **reportlab**: Генерація PDF з Unicode підтримкою

### 4. Алгоритми обробки

#### 4.1 Автоматичне визначення контенту
Система автоматично визначає тип контенту в документі:
- Якщо DOCX містить тільки зображення → запуск OCR
- Якщо PDF містить таблиці → витягнення через Camelot/Tabula
- Якщо зображення без тексту → повідомлення користувачу

#### 4.2 Багатомовна підтримка
Модель mT5 підтримує 101 мову:
- Тренування на паралельних корпусах
- Крос-лінгвальний трансфер
- Адаптація до специфіки мови через fine-tuning

#### 4.3 Оптимізація продуктивності
- **GPU прискорення**: Використання CUDA для швидкої обробки
- **Батчева обробка**: Паралельна обробка чанків
- **Кешування моделі**: Збереження завантаженої моделі в пам'яті

### 5. Метрики якості

#### 5.1 Автоматичні метрики
- **ROUGE**: Перекриття n-грам між згенерованим та референсним резюме
- **BLEU**: Точність перекладу/резюмування
- **BERTScore**: Семантична схожість на основі BERT

#### 5.2 Кількісні показники
- **Стиснення**: Відношення довжини резюме до оригіналу
- **Швидкість**: Токени на секунду
- **Покриття**: Відсоток важливих фактів, збережених у резюме

### 6. Обмеження та перспективи розвитку

#### 6.1 Поточні обмеження
- Залежність від якості OCR
- Обмежена довжина контексту трансформерів
- Необхідність налаштування для специфічних доменів

#### 6.2 Напрямки розвитку
- **Fine-tuning**: Адаптація моделі під специфічні типи документів
- **LoRA**: Low-Rank Adaptation для ефективного донавчання
- **Retrieval-Augmented Generation**: Поєднання з базою знань
- **Multimodal**: Обробка зображень та таблиць як окремих модальностей

### Встановлення

1. Python 3.10+
2. Системні залежності:
   - Tesseract OCR: `choco install tesseract` (Windows) + мовні пакети (ukr, rus, eng)
   - Java Runtime (для PDF-таблиць через Tabula): `choco install openjdk`
3. Python-залежності:

```bash
pip install -r requirements.txt
```

### Використання (Web)

```bash
python manage.py runserver
```

Головна: чат-подібне вікно з полем для тексту або завантаження файлу.
Ліворуч: кнопки «Вхід», «Реєстрація»; після входу — «Історія».

### Підтримувані формати
- **Текст:** `.txt`, `.pdf` (PyMuPDF), `.docx` (python-docx)
- **Таблиці:** `.csv`, `.xlsx` (pandas), вбудовані таблиці в DOCX/PDF
- **Зображення:** `.jpg`/`.png` (OCR), вбудовані зображення в DOCX/PDF

### CLI (додатково)

```bash
python -m summarizer_agent.cli шлях\до\файлу.pdf --interactive --pdf
```

Опції CLI:
- `--model`: модель Hugging Face (за замовчуванням `facebook/bart-large-cnn`)
- `--interactive`: напівінтерактивний режим
- `--parse_docx_tables`, `--ocr_docx_images`: обробка DOCX
- `--parse_pdf_tables`, `--ocr_pdf_images`: обробка PDF
- `--device cuda`: використання GPU
- `--device cpu`: примусове використання CPU
- `--large_text`: оптимізація для великих текстів (автоматично CPU + збільшені чанки)
- `--force_gpu`: примусове використання GPU навіть для великих текстів (може спричинити помилки пам'яті)
- `--no_facts`: не витягувати та не показувати ключові факти
- `--chunk_tokens 512`: розмір чанка в токенах (за замовчуванням 512)
- `--chunk_overlap 100`: перекриття між чанками (за замовчуванням 100)

Приклади для великих текстів:
```bash
# Автоматична оптимізація для великих текстів
python -m summarizer_agent.cli великий_документ.pdf --large_text

# Ручне налаштування для CPU
python -m summarizer_agent.cli документ.txt --device cpu --chunk_tokens 512 --chunk_overlap 100

# Примусове використання GPU з оптимізаціями
python -m summarizer_agent.cli документ.txt --force_gpu --chunk_tokens 256 --chunk_overlap 50

# Без ключових фактів
python -m summarizer_agent.cli документ.txt --no_facts
```


